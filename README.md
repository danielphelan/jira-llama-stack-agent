# Jira-Confluence Requirements Analysis Agent

An intelligent AI agent built on the **Llama Stack framework** that automates requirements analysis, complexity estimation, and technical specification generation for software development teams.

## ğŸ¯ Overview

This agent deeply integrates with **Atlassian's Jira and Confluence** platforms through the **Model Context Protocol (MCP)** to provide:

- âœ… **Automated Requirements Analysis** - Extracts and validates user story requirements
- ğŸ“Š **Smart Story Point Estimation** - Estimates complexity based on historical data
- ğŸ” **Semantic Similarity Search** - Finds related tickets and documentation using Rovo AI
- ğŸ§ª **Test Case Generation** - Creates comprehensive unit, integration, and E2E tests
- ğŸ“ **Technical Spec Generation** - Generates detailed technical design documents
- ğŸ”— **Auto-Linking** - Discovers and links related Jira tickets
- âš ï¸ **Gap Analysis** - Identifies missing requirements across multiple dimensions

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Llama Stack Agent Runtime               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Inference  â”‚  â”‚    Memory    â”‚  â”‚  Safety   â”‚ â”‚
â”‚  â”‚   (Llama     â”‚  â”‚   (Vector    â”‚  â”‚  (Llama   â”‚ â”‚
â”‚  â”‚   3.3 70B)   â”‚  â”‚    Store)    â”‚  â”‚   Guard)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚          Tool/Function Calling Layer          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ Model Context Protocol (MCP)
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Atlassian MCP Server                      â”‚
â”‚  (Anthropic's Official Integration)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OAuth 2.0 Authentication & Session Management      â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Jira Tools  â”‚  â”‚ Confluence   â”‚  â”‚   Rovo    â”‚ â”‚
â”‚  â”‚  (20+ tools) â”‚  â”‚    Tools     â”‚  â”‚  Search   â”‚ â”‚
â”‚  â”‚              â”‚  â”‚  (12+ tools) â”‚  â”‚   (AI)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                â”‚
          â–¼                  â–¼                â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Jira Cloud  â”‚    â”‚ Confluence  â”‚  â”‚  Rovo AI â”‚
   â”‚  REST API   â”‚    â”‚  REST API   â”‚  â”‚  Search  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Installation

### Prerequisites

1. **Python 3.11+**
2. **Node.js 18+** (for Atlassian MCP Server)
3. **Llama Stack** installed and running
4. **Atlassian Account** with:
   - Jira Cloud instance
   - Confluence Cloud instance
   - API token ([Create one here](https://id.atlassian.com/manage-profile/security/api-tokens))

### Step 1: Clone Repository

```bash
git clone https://github.com/your-org/jira-llama-stack-agent.git
cd jira-llama-stack-agent
```

### Step 2: Install Python Dependencies

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Step 3: Install Atlassian MCP Server

```bash
# Install globally
npm install -g @anthropic/atlassian-mcp-server

# Or use npx (no installation required)
# The agent will use npx by default
```

### Step 4: Configure Environment

```bash
# Copy example environment file
cp .env.example .env

# Edit .env with your credentials
nano .env  # or your preferred editor
```

**Required environment variables:**

```bash
# Atlassian Configuration
ATLASSIAN_INSTANCE_URL=https://your-domain.atlassian.net
ATLASSIAN_EMAIL=your-email@company.com
ATLASSIAN_API_TOKEN=your-api-token-here

# Llama Stack Configuration
LLAMA_STACK_BASE_URL=http://localhost:5000

# Optional: Model Configuration
MODEL_NAME=meta-llama/Llama-3.3-70B-Instruct
```

### Step 5: Install and Start Llama Stack

```bash
# Install Llama Stack if not already installed
pip install llama-stack llama-stack-client

# Initialize Llama Stack project (if first time)
llama stack init requirements-agent

# Download and configure Llama 3.3 70B model
llama stack download-model meta-llama/Llama-3.3-70B-Instruct

# Start Llama Stack server
llama stack run --config config/agent_config.yaml --mcp-config config/mcp_config.json
```

**Note:** The Llama Stack server must be running before using the agent.

## ğŸš€ Quick Start

### Test Connection

```python
python example_usage.py
```

This will run a health check to verify:
- âœ… MCP connection to Atlassian
- âœ… Llama Stack inference availability
- âœ… Authentication status

### Analyze a Single Story

```python
import asyncio
from src.agent.core import RequirementsAgent

async def main():
    # Initialize agent
    agent = RequirementsAgent(config_path="config/agent_config.yaml")

    # Analyze a story
    results = await agent.analyze_story(
        ticket_id="PROJ-123",
        post_comment=True,
        estimate_points=True,
        generate_tests=True
    )

    if results["success"]:
        print(f"âœ… Analysis complete!")
        print(f"Completeness: {results['analysis'].completeness_score}/10")
        print(f"Story Points: {results['estimation'].estimated_points}")
        print(f"Test Cases: {results['tests'].total_test_cases}")

asyncio.run(main())
```

### Batch Analysis

```python
async def batch_analysis():
    agent = RequirementsAgent()

    ticket_ids = ["PROJ-123", "PROJ-124", "PROJ-125"]

    results = await agent.batch_analyze_stories(
        ticket_ids=ticket_ids,
        post_comments=True
    )

    print(f"Successful: {results['successful']}/{results['total']}")

asyncio.run(batch_analysis())
```

### Generate Epic Technical Specification

```python
async def generate_spec():
    agent = RequirementsAgent()

    results = await agent.generate_epic_spec(
        epic_id="PROJ-100",
        confluence_space="TECH",
        post_to_confluence=True
    )

    if results["success"]:
        print(f"Spec created: {results['confluence_url']}")

asyncio.run(generate_spec())
```

## ğŸ“– Features

### 1. Story Analysis (FR-1.1, FR-1.2)

Analyzes user stories and extracts:
- Actors, actions, and business value
- Implicit requirements
- Acceptance criteria gaps
- Missing requirements by category:
  - Functional
  - Security
  - Performance
  - Accessibility
  - Error handling
  - Edge cases

**Example Output:**

```json
{
  "actors": ["user", "admin"],
  "actions": ["create", "submit", "validate"],
  "business_value": "Reduce processing time by 50%",
  "completeness_score": 8.5,
  "missing_requirements": {
    "security": ["No mention of data encryption"],
    "performance": ["No response time requirement"],
    "accessibility": ["WCAG compliance not specified"]
  }
}
```

### 2. Story Point Estimation (FR-3.1)

Estimates complexity based on:
- Similar historical stories (via Rovo search)
- Number of acceptance criteria
- Component complexity
- Integration points
- Testing requirements

**Example Output:**

```json
{
  "estimated_points": 5,
  "confidence": 0.78,
  "confidence_interval": [3, 8],
  "reasoning": "Similar to PROJ-456 (5 pts) with additional API integration",
  "similar_stories_analyzed": 15
}
```

### 3. Test Case Generation (FR-6.1)

Generates comprehensive test suites:
- **Unit Tests:** Business logic, validation, edge cases
- **Integration Tests:** API contracts, database interactions
- **E2E Tests:** User journeys, cross-browser scenarios
- **QA Scenarios:** Manual test procedures with steps

**Example Output:**

```json
{
  "total_test_cases": 24,
  "unit_tests": [
    {
      "test_id": "UT-001",
      "test_name": "test_validates_email_format",
      "given": "User submits form with invalid email",
      "when": "Form validation runs",
      "then": "Error message displayed",
      "code_snippet": "// Jest test code..."
    }
  ],
  "coverage_analysis": {
    "acceptance_criteria_covered": "92%"
  }
}
```

### 4. Semantic Similarity Search (FR-2.1)

Uses **Atlassian Rovo AI** for intelligent search:
- Finds similar past Jira stories
- Discovers related Confluence documentation
- Semantic understanding (not just keywords)
- Context-aware relevance ranking

**Example:**

```python
# Search for similar issues
similar_issues = await atlassian.search_similar_issues(
    summary="Implement user authentication",
    description="OAuth 2.0 integration",
    limit=5
)

# Search for technical docs
similar_docs = await atlassian.search_similar_confluence_docs(
    query="Authentication architecture and implementation",
    space_key="TECH"
)
```

### 5. Auto-Linking (FR-2.2)

Automatically discovers and links related tickets:
- Similar stories (Rovo semantic match)
- Same Epic siblings
- Component/label matches
- Referenced in Confluence docs

### 6. Technical Spec Generation (FR-4.1)

Generates comprehensive technical design documents:
- Architecture diagrams (Mermaid)
- API specifications
- Data models
- Testing strategy
- Deployment plan
- Monitoring requirements

## âš™ï¸ Configuration

### Agent Configuration (`config/agent_config.yaml`)

```yaml
llama_stack:
  model:
    name: "meta-llama/Llama-3.3-70B-Instruct"
    temperature: 0.7
    max_tokens: 4096

features:
  auto_analysis:
    enabled: true
    trigger_on_story_create: true

  estimation:
    enabled: true
    story_point_scale: [1, 2, 3, 5, 8, 13]

  test_generation:
    enabled: true
    include_unit_tests: true
    include_e2e_tests: true

thresholds:
  completeness_score_minimum: 7.0
  estimation_confidence_minimum: 0.70
```

### MCP Configuration (`config/mcp_config.json`)

```json
{
  "mcpServers": {
    "atlassian": {
      "command": "npx",
      "args": ["-y", "@anthropic/atlassian-mcp-server"],
      "env": {
        "ATLASSIAN_INSTANCE_URL": "${ATLASSIAN_INSTANCE_URL}",
        "ATLASSIAN_EMAIL": "${ATLASSIAN_EMAIL}",
        "ATLASSIAN_API_TOKEN": "${ATLASSIAN_API_TOKEN}"
      }
    }
  }
}
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/test_agent_tools.py
```

## ğŸ“Š Performance

- **Story Analysis:** < 30 seconds
- **Rovo Search:** < 5 seconds
- **Test Generation:** < 60 seconds
- **Epic Spec Generation:** < 2 minutes
- **Batch Processing:** 50+ stories/hour

## ğŸ”’ Security

- OAuth 2.0 authentication only
- API tokens stored in environment variables
- Llama Guard for content safety
- Audit logging for all operations
- PII detection and handling

## ğŸ“ Project Structure

```
jira-llama-stack-agent/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ agent_config.yaml       # Agent configuration
â”‚   â””â”€â”€ mcp_config.json         # MCP server configuration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ core.py            # Main agent orchestration
â”‚   â”‚   â””â”€â”€ tools.py           # Analysis tool implementations
â”‚   â”œâ”€â”€ integrations/
â”‚   â”‚   â”œâ”€â”€ mcp_client.py      # MCP client wrapper
â”‚   â”‚   â””â”€â”€ atlassian_tools.py # High-level Atlassian tools
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ system_prompts.py  # System prompts
â”‚   â”‚   â””â”€â”€ task_prompts.py    # Task-specific prompts
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logging.py         # Logging configuration
â”‚       â””â”€â”€ helpers.py         # Utility functions
â”œâ”€â”€ tests/                      # Test suite
â”œâ”€â”€ example_usage.py           # Usage examples
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env.example              # Environment template
â””â”€â”€ README.md                 # This file
```

## ğŸ› ï¸ Development

### Adding Custom Tools

```python
# src/agent/tools.py

async def custom_analysis_tool(self, ticket_id: str):
    """Your custom analysis logic."""
    # 1. Fetch data using MCP tools
    context = await self.atlassian.get_story_with_context(ticket_id)

    # 2. Call LLM with custom prompt
    response = await self.llama.inference.chat_completion(
        model=self.model,
        messages=[{"role": "user", "content": "..."}]
    )

    # 3. Parse and return results
    return results
```

### Customizing Prompts

Edit prompts in `src/prompts/task_prompts.py`:

```python
def CUSTOM_PROMPT(context: dict) -> str:
    return f"""
    Your custom prompt with {context}
    """
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- **Meta AI** - Llama 3.3 model
- **Anthropic** - MCP protocol and Atlassian integration
- **Atlassian** - Rovo AI search and platform APIs

## ğŸ“ Support

- **Documentation:** [Full PRD](docs/PRD.md)
- **Issues:** [GitHub Issues](https://github.com/your-org/jira-llama-stack-agent/issues)
- **Slack:** #llama-stack-agent

## ğŸ—ºï¸ Roadmap

### Phase 1: Foundation âœ… (Current)
- [x] Basic story analysis
- [x] MCP integration
- [x] Test case generation
- [x] Story point estimation

### Phase 2: Intelligence Layer (Weeks 4-6)
- [ ] Advanced Rovo search integration
- [ ] ML-based estimation refinement
- [ ] Auto-linking improvements
- [ ] Requirements gap analysis

### Phase 3: Content Generation (Weeks 7-9)
- [ ] Auto-generate descriptions
- [ ] Auto-generate acceptance criteria
- [ ] Epic technical specs
- [ ] Architecture diagrams

### Phase 4: Optimization (Weeks 10-12)
- [ ] Performance optimization
- [ ] Batch processing at scale
- [ ] Analytics dashboard
- [ ] Fine-tuning on company data

---

**Built with â¤ï¸ using Llama Stack and the Model Context Protocol**
